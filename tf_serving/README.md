# Wide & Deep CTR æ¨¡å‹ TensorFlow Serving éƒ¨ç½²

æœ¬ç›®å½•åŒ…å«å°† Wide & Deep CTR æ¨¡å‹éƒ¨ç½²åˆ° TensorFlow Serving çš„æ‰€æœ‰å¿…è¦æ–‡ä»¶ã€‚

## ğŸ“ æ–‡ä»¶ç»“æ„

```
tf_serving/
â”œâ”€â”€ README.md              # æœ¬æ–‡æ¡£
â”œâ”€â”€ Dockerfile             # Docker é•œåƒæ„å»ºæ–‡ä»¶
â”œâ”€â”€ docker-compose.yml     # Docker Compose é…ç½®
â”œâ”€â”€ models.config          # TensorFlow Serving æ¨¡å‹é…ç½®
â”œâ”€â”€ export_model.py        # æ¨¡å‹å¯¼å‡ºè„šæœ¬
â”œâ”€â”€ client_example.py      # Python å®¢æˆ·ç«¯ç¤ºä¾‹
â”œâ”€â”€ build_and_run.sh       # ä¸€é”®æ„å»ºè¿è¡Œè„šæœ¬
â””â”€â”€ exported_models/       # å¯¼å‡ºçš„æ¨¡å‹ç›®å½•
    â””â”€â”€ wide_deep_ctr/
        â””â”€â”€ 1/             # æ¨¡å‹ç‰ˆæœ¬ 1
            â”œâ”€â”€ saved_model.pb
            â””â”€â”€ variables/
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šä¸€é”®éƒ¨ç½²ï¼ˆæ¨èï¼‰

```bash
cd tf_serving
chmod +x build_and_run.sh
./build_and_run.sh
```

### æ–¹å¼äºŒï¼šæ‰‹åŠ¨éƒ¨ç½²

#### 1. å¯¼å‡ºæ¨¡å‹

å¦‚æœä½ å·²ç»è®­ç»ƒäº† Wide & Deep æ¨¡å‹ï¼š

```bash
# å¯¼å‡ºå·²è®­ç»ƒçš„æ¨¡å‹
python export_model.py --input models/wide_deep_ctr_model.h5

# æˆ–åˆ›å»ºç¤ºä¾‹æ¨¡å‹ç”¨äºæµ‹è¯•
python export_model.py --create-sample
```

#### 2. æ„å»º Docker é•œåƒ

```bash
docker build -t wide-deep-serving .
```

#### 3. è¿è¡Œå®¹å™¨

```bash
docker run -d \
  --name wide-deep-ctr-serving \
  -p 8500:8500 \
  -p 8501:8501 \
  wide-deep-serving
```

#### 4. éªŒè¯æœåŠ¡

```bash
# æ£€æŸ¥æ¨¡å‹çŠ¶æ€
curl http://localhost:8501/v1/models/wide_deep_ctr

# æŸ¥çœ‹æ¨¡å‹å…ƒæ•°æ®
curl http://localhost:8501/v1/models/wide_deep_ctr/metadata
```

## ğŸ“¡ API æ¥å£

### REST API (ç«¯å£ 8501)

#### æ¨¡å‹çŠ¶æ€

```bash
GET http://localhost:8501/v1/models/wide_deep_ctr
```

å“åº”ç¤ºä¾‹ï¼š
```json
{
  "model_version_status": [
    {
      "version": "1",
      "state": "AVAILABLE",
      "status": {
        "error_code": "OK",
        "error_message": ""
      }
    }
  ]
}
```

#### å•æ ·æœ¬é¢„æµ‹

```bash
POST http://localhost:8501/v1/models/wide_deep_ctr:predict
Content-Type: application/json

{
  "instances": [{
    "wide": [1.0, 0.5, 0.8, 0.3, 0.1, 0.2],
    "deep": [10.0, 5.0, 20.0, 3.0, 8.0, 0.5, 0.6, 0.1],
    "query_hash": 123,
    "doc_hash": 456,
    "position_group": 0
  }]
}
```

å“åº”ç¤ºä¾‹ï¼š
```json
{
  "predictions": [[0.7523456]]
}
```

#### æ‰¹é‡é¢„æµ‹

```bash
POST http://localhost:8501/v1/models/wide_deep_ctr:predict
Content-Type: application/json

{
  "instances": [
    {
      "wide": [1.0, 0.5, 0.8, 0.3, 0.1, 0.2],
      "deep": [10.0, 5.0, 20.0, 3.0, 8.0, 0.5, 0.6, 0.1],
      "query_hash": 123,
      "doc_hash": 456,
      "position_group": 0
    },
    {
      "wide": [2.0, 0.3, 0.6, 0.5, 0.2, 0.1],
      "deep": [15.0, 8.0, 25.0, 5.0, 10.0, 0.7, 0.4, 0.2],
      "query_hash": 789,
      "doc_hash": 101,
      "position_group": 1
    }
  ]
}
```

#### æŒ‡å®šç‰ˆæœ¬é¢„æµ‹

```bash
POST http://localhost:8501/v1/models/wide_deep_ctr/versions/1:predict
```

### gRPC API (ç«¯å£ 8500)

gRPC æä¾›æ›´é«˜æ€§èƒ½çš„è°ƒç”¨æ–¹å¼ï¼Œé€‚åˆé«˜å¹¶å‘åœºæ™¯ã€‚

```python
import grpc
from tensorflow_serving.apis import predict_pb2
from tensorflow_serving.apis import prediction_service_pb2_grpc

# åˆ›å»º gRPC channel
channel = grpc.insecure_channel('localhost:8500')
stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)

# æ„å»ºè¯·æ±‚
request = predict_pb2.PredictRequest()
request.model_spec.name = 'wide_deep_ctr'
request.model_spec.signature_name = 'serving_default'
# ... è®¾ç½®è¾“å…¥å¼ é‡ ...

# å‘é€è¯·æ±‚
response = stub.Predict(request)
```

## ğŸ“Š è¾“å…¥ç‰¹å¾è¯´æ˜

| ç‰¹å¾å | ç±»å‹ | ç»´åº¦ | è¯´æ˜ |
|-------|------|------|------|
| `wide` | float32 | [6] | Wide çº¿æ€§ç‰¹å¾ï¼ˆä½ç½®ã€åˆ†æ•°ã€åŒ¹é…åº¦ç­‰ï¼‰ |
| `deep` | float32 | [8] | Deep éçº¿æ€§ç‰¹å¾ï¼ˆé•¿åº¦ã€è¯æ•°ã€æ—¶é—´ç­‰ï¼‰ |
| `query_hash` | int32 | [] | æŸ¥è¯¢å“ˆå¸Œå€¼ (0-999) |
| `doc_hash` | int32 | [] | æ–‡æ¡£å“ˆå¸Œå€¼ (0-999) |
| `position_group` | int32 | [] | ä½ç½®åˆ†ç»„ (0=å¤´éƒ¨, 1=ä¸­éƒ¨, 2=å°¾éƒ¨) |

### Wide ç‰¹å¾è¯¦æƒ… (6ç»´)

1. ä½ç½® (position)
2. ä½ç½®è¡°å‡ (1/(position+1))
3. åŸå§‹ç›¸ä¼¼åº¦åˆ†æ•° (score)
4. æŸ¥è¯¢åŒ¹é…åº¦ (query-summary overlap)
5. æŸ¥è¯¢å†å²CTR
6. æ–‡æ¡£å†å²CTR

### Deep ç‰¹å¾è¯¦æƒ… (8ç»´)

1. æ–‡æ¡£é•¿åº¦ (doc_length)
2. æŸ¥è¯¢é•¿åº¦ (query_length)
3. æ‘˜è¦é•¿åº¦ (summary_length)
4. æŸ¥è¯¢è¯æ•° (query_word_count)
5. æ‘˜è¦è¯æ•° (summary_word_count)
6. æ—¶é—´ç‰¹å¾ (time_feature)
7. ä½ç½®Ã—åˆ†æ•°äº¤å‰ç‰¹å¾
8. æŸ¥è¯¢é•¿åº¦Ã—åŒ¹é…åº¦äº¤å‰ç‰¹å¾

## ğŸ”§ æ¨¡å‹ç‰ˆæœ¬ç®¡ç†

### éƒ¨ç½²æ–°ç‰ˆæœ¬

1. å¯¼å‡ºæ–°æ¨¡å‹åˆ°æ–°ç‰ˆæœ¬ç›®å½•ï¼š
```bash
python export_model.py --version 2
```

2. TensorFlow Serving ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶åŠ è½½æ–°ç‰ˆæœ¬

### å›æ»šåˆ°æ—§ç‰ˆæœ¬

ä¿®æ”¹ `models.config`ï¼ŒæŒ‡å®šåŠ è½½ç‰¹å®šç‰ˆæœ¬ï¼š

```protobuf
model_version_policy {
  specific {
    versions: 1
  }
}
```

### A/B æµ‹è¯•

ä½¿ç”¨ç‰ˆæœ¬æ ‡ç­¾è¿›è¡Œæµé‡åˆ†é…ï¼š

```protobuf
version_labels {
  key: "stable"
  value: 1
}
version_labels {
  key: "canary"
  value: 2
}
```

## ğŸ› ï¸ è¿ç»´å‘½ä»¤

```bash
# æŸ¥çœ‹å®¹å™¨çŠ¶æ€
docker ps | grep wide-deep

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
docker logs -f wide-deep-ctr-serving

# è¿›å…¥å®¹å™¨
docker exec -it wide-deep-ctr-serving /bin/bash

# é‡å¯æœåŠ¡
docker restart wide-deep-ctr-serving

# åœæ­¢æœåŠ¡
docker stop wide-deep-ctr-serving

# åˆ é™¤å®¹å™¨
docker rm -f wide-deep-ctr-serving
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. å¯ç”¨æ‰¹å¤„ç†

ç¼–è¾‘ Dockerfileï¼Œæ·»åŠ æ‰¹å¤„ç†å‚æ•°ï¼š

```dockerfile
CMD ["--port=8500", \
     "--rest_api_port=8501", \
     "--model_config_file=/models/models.config", \
     "--enable_batching=true", \
     "--batching_parameters_file=/models/batching.config"]
```

åˆ›å»º `batching.config`ï¼š

```protobuf
max_batch_size { value: 32 }
batch_timeout_micros { value: 5000 }
num_batch_threads { value: 4 }
```

### 2. GPU åŠ é€Ÿ

ä½¿ç”¨ GPU ç‰ˆæœ¬çš„ TensorFlow Servingï¼š

```dockerfile
FROM tensorflow/serving:2.14.0-gpu
```

è¿è¡Œæ—¶æŒ‚è½½ GPUï¼š

```bash
docker run --gpus all -p 8501:8501 wide-deep-serving
```

### 3. å¤šå®ä¾‹è´Ÿè½½å‡è¡¡

ä½¿ç”¨ Docker Compose æˆ– Kubernetes éƒ¨ç½²å¤šä¸ªå®ä¾‹ï¼Œé…åˆ Nginx æˆ– Envoy è¿›è¡Œè´Ÿè½½å‡è¡¡ã€‚

## ğŸ” æ•…éšœæ’æŸ¥

### æœåŠ¡æ— æ³•å¯åŠ¨

```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
docker logs wide-deep-ctr-serving

# å¸¸è§é—®é¢˜ï¼š
# 1. ç«¯å£è¢«å ç”¨ -> ä¿®æ”¹ç«¯å£æ˜ å°„
# 2. æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ -> æ£€æŸ¥ exported_models ç›®å½•
# 3. æ¨¡å‹æ ¼å¼é”™è¯¯ -> é‡æ–°å¯¼å‡ºæ¨¡å‹
```

### é¢„æµ‹è¿”å›é”™è¯¯

```bash
# æ£€æŸ¥æ¨¡å‹çŠ¶æ€
curl http://localhost:8501/v1/models/wide_deep_ctr

# æŸ¥çœ‹æ¨¡å‹ç­¾å
curl http://localhost:8501/v1/models/wide_deep_ctr/metadata

# å¸¸è§é—®é¢˜ï¼š
# 1. è¾“å…¥ç»´åº¦ä¸åŒ¹é… -> æ£€æŸ¥ wide/deep ç‰¹å¾ç»´åº¦
# 2. æ•°æ®ç±»å‹é”™è¯¯ -> ç¡®ä¿ query_hash ç­‰ä¸ºæ•´æ•°
```

## ğŸ“š å‚è€ƒèµ„æ–™

- [TensorFlow Serving å®˜æ–¹æ–‡æ¡£](https://www.tensorflow.org/tfx/guide/serving)
- [TensorFlow Serving REST API](https://www.tensorflow.org/tfx/serving/api_rest)
- [TensorFlow Serving é…ç½®](https://www.tensorflow.org/tfx/serving/serving_config)
- [Wide & Deep è®ºæ–‡](https://arxiv.org/abs/1606.07792)
