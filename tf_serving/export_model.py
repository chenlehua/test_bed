#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Wide & Deep æ¨¡å‹å¯¼å‡ºè„šæœ¬
å°†è®­ç»ƒå¥½çš„ Wide & Deep æ¨¡å‹å¯¼å‡ºä¸º TensorFlow Serving å¯ç”¨çš„ SavedModel æ ¼å¼
"""

import os
import sys
import argparse
import shutil
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

try:
    import tensorflow as tf
    from tensorflow import keras
except ImportError:
    print("âŒ TensorFlow æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install tensorflow")
    sys.exit(1)


def export_wide_deep_model(
    input_model_path: str = "models/wide_deep_ctr_model.h5",
    output_dir: str = "tf_serving/exported_models/wide_deep_ctr",
    version: int = None
):
    """
    å¯¼å‡º Wide & Deep æ¨¡å‹ä¸º TensorFlow Serving SavedModel æ ¼å¼
    
    Args:
        input_model_path: è¾“å…¥æ¨¡å‹è·¯å¾„ (.h5 æ ¼å¼)
        output_dir: è¾“å‡ºç›®å½•
        version: æ¨¡å‹ç‰ˆæœ¬å·ï¼ˆé»˜è®¤ä½¿ç”¨æ—¶é—´æˆ³ï¼‰
    """
    print("=" * 60)
    print("ğŸš€ Wide & Deep æ¨¡å‹å¯¼å‡ºå·¥å…·")
    print("=" * 60)
    
    # æ£€æŸ¥è¾“å…¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {input_model_path}")
        print("\nğŸ’¡ æç¤ºï¼šè¯·å…ˆè®­ç»ƒ Wide & Deep æ¨¡å‹ï¼Œæˆ–æŒ‡å®šæ­£ç¡®çš„æ¨¡å‹è·¯å¾„")
        print("   è®­ç»ƒå‘½ä»¤: åœ¨ç³»ç»Ÿ UI ä¸­ä½¿ç”¨ Training æ ‡ç­¾é¡µè®­ç»ƒæ¨¡å‹")
        return False
    
    print(f"ğŸ“‚ è¾“å…¥æ¨¡å‹: {input_model_path}")
    
    try:
        # åŠ è½½æ¨¡å‹
        print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
        model = keras.models.load_model(input_model_path)
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        print(f"\nğŸ“‹ æ¨¡å‹ä¿¡æ¯:")
        print(f"   è¾“å…¥å±‚: {[layer.name for layer in model.inputs]}")
        print(f"   è¾“å‡ºå±‚: {[layer.name for layer in model.outputs]}")
        
        # ç”Ÿæˆç‰ˆæœ¬å·
        if version is None:
            version = int(datetime.now().strftime("%Y%m%d%H%M%S"))
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        version_dir = os.path.join(output_dir, str(version))
        os.makedirs(version_dir, exist_ok=True)
        
        print(f"\nğŸ“¤ å¯¼å‡ºæ¨¡å‹åˆ°: {version_dir}")
        
        # å¯¼å‡ºä¸º SavedModel æ ¼å¼
        model.save(version_dir, save_format='tf')
        
        print(f"âœ… æ¨¡å‹å¯¼å‡ºæˆåŠŸ!")
        print(f"\nğŸ“Š å¯¼å‡ºä¿¡æ¯:")
        print(f"   æ¨¡å‹è·¯å¾„: {version_dir}")
        print(f"   æ¨¡å‹ç‰ˆæœ¬: {version}")
        print(f"   æ ¼å¼: TensorFlow SavedModel")
        
        # éªŒè¯å¯¼å‡ºçš„æ¨¡å‹
        print(f"\nğŸ” éªŒè¯å¯¼å‡ºçš„æ¨¡å‹...")
        loaded_model = tf.saved_model.load(version_dir)
        print(f"âœ… æ¨¡å‹éªŒè¯æˆåŠŸ")
        
        # æ‰“å°ç­¾åä¿¡æ¯
        if hasattr(loaded_model, 'signatures'):
            print(f"\nğŸ“ æ¨¡å‹ç­¾å:")
            for sig_name in loaded_model.signatures.keys():
                print(f"   - {sig_name}")
        
        print("\n" + "=" * 60)
        print("ğŸ‰ å¯¼å‡ºå®Œæˆ! å¯ä»¥ä½¿ç”¨ TensorFlow Serving éƒ¨ç½²æ­¤æ¨¡å‹")
        print("=" * 60)
        
        return True
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def create_sample_model_for_testing(output_dir: str = "tf_serving/exported_models/wide_deep_ctr"):
    """
    åˆ›å»ºä¸€ä¸ªç¤ºä¾‹æ¨¡å‹ç”¨äºæµ‹è¯•ï¼ˆå½“æ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹æ—¶ï¼‰
    """
    print("=" * 60)
    print("ğŸ”§ åˆ›å»ºç¤ºä¾‹ Wide & Deep æ¨¡å‹ç”¨äºæµ‹è¯•")
    print("=" * 60)
    
    try:
        # æ¨¡å‹å‚æ•°
        wide_dim = 6  # Wide ç‰¹å¾ç»´åº¦
        deep_dim = 8  # Deep ç‰¹å¾ç»´åº¦
        vocab_sizes = {
            'query_hash': 1000,
            'doc_hash': 1000,
            'position_group': 3
        }
        
        # Wideéƒ¨åˆ†è¾“å…¥
        wide_input = keras.Input(shape=(wide_dim,), name='wide')
        
        # Deepéƒ¨åˆ†è¾“å…¥
        deep_input = keras.Input(shape=(deep_dim,), name='deep')
        
        # åˆ†ç±»ç‰¹å¾è¾“å…¥
        query_input = keras.Input(shape=(), name='query_hash', dtype='int32')
        doc_input = keras.Input(shape=(), name='doc_hash', dtype='int32')
        position_input = keras.Input(shape=(), name='position_group', dtype='int32')
        
        # åµŒå…¥å±‚
        query_embedding = keras.layers.Embedding(vocab_sizes['query_hash'], 8)(query_input)
        doc_embedding = keras.layers.Embedding(vocab_sizes['doc_hash'], 8)(doc_input)
        position_embedding = keras.layers.Embedding(vocab_sizes['position_group'], 4)(position_input)
        
        # å±•å¹³
        query_flat = keras.layers.Flatten()(query_embedding)
        doc_flat = keras.layers.Flatten()(doc_embedding)
        position_flat = keras.layers.Flatten()(position_embedding)
        
        # Deepéƒ¨åˆ†
        deep_concat = keras.layers.Concatenate()([deep_input, query_flat, doc_flat, position_flat])
        deep_hidden1 = keras.layers.Dense(128, activation='relu')(deep_concat)
        deep_hidden2 = keras.layers.Dense(64, activation='relu')(deep_hidden1)
        deep_hidden3 = keras.layers.Dense(32, activation='relu')(deep_hidden2)
        
        # Wide & Deep åˆå¹¶
        wide_deep_concat = keras.layers.Concatenate()([wide_input, deep_hidden3])
        
        # è¾“å‡ºå±‚
        output = keras.layers.Dense(1, activation='sigmoid', name='output')(wide_deep_concat)
        
        # åˆ›å»ºæ¨¡å‹
        model = keras.Model(
            inputs=[wide_input, deep_input, query_input, doc_input, position_input],
            outputs=output,
            name='wide_and_deep_ctr'
        )
        
        # ç¼–è¯‘æ¨¡å‹
        model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        
        # ç”Ÿæˆç‰ˆæœ¬å·
        version = 1
        version_dir = os.path.join(output_dir, str(version))
        
        # æ¸…ç†å·²å­˜åœ¨çš„ç›®å½•
        if os.path.exists(version_dir):
            shutil.rmtree(version_dir)
        
        os.makedirs(version_dir, exist_ok=True)
        
        # å¯¼å‡ºæ¨¡å‹
        print(f"ğŸ“¤ å¯¼å‡ºç¤ºä¾‹æ¨¡å‹åˆ°: {version_dir}")
        model.save(version_dir, save_format='tf')
        
        print(f"âœ… ç¤ºä¾‹æ¨¡å‹åˆ›å»ºæˆåŠŸ!")
        print(f"\nğŸ“‹ æ¨¡å‹ä¿¡æ¯:")
        print(f"   Wide ç‰¹å¾ç»´åº¦: {wide_dim}")
        print(f"   Deep ç‰¹å¾ç»´åº¦: {deep_dim}")
        print(f"   Query Hash æ¡¶æ•°: {vocab_sizes['query_hash']}")
        print(f"   Doc Hash æ¡¶æ•°: {vocab_sizes['doc_hash']}")
        print(f"   Position åˆ†ç»„æ•°: {vocab_sizes['position_group']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºç¤ºä¾‹æ¨¡å‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    parser = argparse.ArgumentParser(description='Wide & Deep æ¨¡å‹å¯¼å‡ºå·¥å…·')
    parser.add_argument(
        '--input', '-i',
        type=str,
        default='models/wide_deep_ctr_model.h5',
        help='è¾“å…¥æ¨¡å‹è·¯å¾„ (.h5 æ ¼å¼)'
    )
    parser.add_argument(
        '--output', '-o',
        type=str,
        default='tf_serving/exported_models/wide_deep_ctr',
        help='è¾“å‡ºç›®å½•'
    )
    parser.add_argument(
        '--version', '-v',
        type=int,
        default=None,
        help='æ¨¡å‹ç‰ˆæœ¬å· (é»˜è®¤ä½¿ç”¨æ—¶é—´æˆ³)'
    )
    parser.add_argument(
        '--create-sample',
        action='store_true',
        help='åˆ›å»ºç¤ºä¾‹æ¨¡å‹ç”¨äºæµ‹è¯•'
    )
    
    args = parser.parse_args()
    
    if args.create_sample:
        success = create_sample_model_for_testing(args.output)
    else:
        success = export_wide_deep_model(args.input, args.output, args.version)
    
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
